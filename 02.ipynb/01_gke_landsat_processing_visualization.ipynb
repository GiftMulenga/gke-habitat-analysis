{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc053c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "GKE Landsat Processing, Visualization, and Export Script\n",
    "================================================================================\n",
    "\n",
    "Purpose: Process and visualize Landsat data for habitat loss analysis (1984-2024)\n",
    "         in the Greater Kafue Ecosystem, Zambia.\n",
    "\n",
    "Components:\n",
    "    Part 1: GKELandsatVisualization - Process and visualize Landsat composites\n",
    "    Part 2: GKELandsatExporter - Export composites to Google Drive\n",
    "\n",
    "Author: Gift Mulenga\n",
    "Institution: Copperbelt University, Zambia\n",
    "Research: MSc Thesis - Tropical Ecology\n",
    "\n",
    "Requirements:\n",
    "    - earthengine-api\n",
    "    - geemap\n",
    "    - geopandas\n",
    "    - pickle\n",
    "    \n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "import geemap\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0091b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate \n",
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Earth Engine\n",
    "try:\n",
    "    ee.Initialize()\n",
    "    print(\"Earth Engine initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Earth Engine: {e}\")\n",
    "    print(\"Please authenticate with: ee.Authenticate()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa11864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LANDSAT VISUALIZATION CLASS\n",
    "# =============================================================================\n",
    "\n",
    "class GKELandsatVisualization:\n",
    "    \"\"\"\n",
    "    Process and visualize Landsat data for the Greater Kafue Ecosystem.\n",
    "    \n",
    "    This class handles:\n",
    "        - Loading study area boundaries from shapefiles\n",
    "        - Retrieving appropriate Landsat collections by year\n",
    "        - Creating cloud-free median composites\n",
    "        - Interactive visualization with geemap\n",
    "        - Saving processor state for export\n",
    "    \n",
    "    Attributes:\n",
    "        shapefile_path (str): Path to GKE boundary shapefile\n",
    "        output_folder (str): Local folder for saving processor state\n",
    "        cloud_threshold (int): Maximum cloud cover percentage (0-100)\n",
    "        target_configs (dict): Date ranges for each target year\n",
    "        study_area: Earth Engine geometry of study area\n",
    "        map: geemap Map instance\n",
    "        composites (dict): Processed composites by year\n",
    "        configs (dict): Configuration metadata by year\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, shapefile_path, output_folder, cloud_threshold=1):\n",
    "        \"\"\"\n",
    "        Initialize the GKE Landsat processor for visualization.\n",
    "        \n",
    "        Args:\n",
    "            shapefile_path (str): Path to GKE boundary shapefile\n",
    "            output_folder (str): Local folder for saving processor state\n",
    "            cloud_threshold (int): Maximum cloud cover percentage (0-100)\n",
    "        \"\"\"\n",
    "        self.shapefile_path = shapefile_path\n",
    "        self.output_folder = output_folder\n",
    "        self.study_area = None\n",
    "        self.map = None\n",
    "        \n",
    "        # Target years and date ranges for dry season composites\n",
    "        self.target_configs = {\n",
    "            1984: {'start_date': '1984-05-01', 'end_date': '1984-08-31'},\n",
    "            1994: {'start_date': '1994-05-01', 'end_date': '1994-08-31'},\n",
    "            2004: {'start_date': '2004-05-01', 'end_date': '2004-08-31'},\n",
    "            2014: {'start_date': '2014-05-01', 'end_date': '2014-08-31'},\n",
    "            2024: {'start_date': '2024-05-01', 'end_date': '2024-06-30'}\n",
    "        }\n",
    "        \n",
    "        self.cloud_threshold = cloud_threshold\n",
    "\n",
    "    def update_date_range(self, year, start_date, end_date):\n",
    "        \"\"\"\n",
    "        Update date range for a specific year.\n",
    "        \n",
    "        Args:\n",
    "            year (int): Target year\n",
    "            start_date (str): Start date in 'YYYY-MM-DD' format\n",
    "            end_date (str): End date in 'YYYY-MM-DD' format\n",
    "        \"\"\"\n",
    "        if year in self.target_configs:\n",
    "            self.target_configs[year]['start_date'] = start_date\n",
    "            self.target_configs[year]['end_date'] = end_date\n",
    "            print(f\"Updated {year} date range: {start_date} to {end_date}\")\n",
    "        else:\n",
    "            print(f\"Year {year} not found in target configurations\")\n",
    "    \n",
    "    def update_cloud_threshold(self, threshold):\n",
    "        \"\"\"\n",
    "        Update cloud cover threshold.\n",
    "        \n",
    "        Args:\n",
    "            threshold (int): Maximum cloud cover percentage (0-100)\n",
    "        \"\"\"\n",
    "        self.cloud_threshold = threshold\n",
    "        print(f\"Updated cloud cover threshold to {threshold}%\")\n",
    "        \n",
    "    def load_study_area(self):\n",
    "        \"\"\"\n",
    "        Load GKE boundary shapefile and convert to Earth Engine geometry.\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if successful, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            gdf = gpd.read_file(self.shapefile_path)\n",
    "\n",
    "            if gdf.crs != 'EPSG:4326':\n",
    "                gdf = gdf.to_crs('EPSG:4326')\n",
    "\n",
    "            geojson = json.loads(gdf.to_json())\n",
    "            coords = []\n",
    "            for feature in geojson['features']:\n",
    "                geom = feature['geometry']\n",
    "                if geom['type'] == 'Polygon':\n",
    "                    coords.extend(geom['coordinates'][0])\n",
    "                elif geom['type'] == 'MultiPolygon':\n",
    "                    for polygon in geom['coordinates']:\n",
    "                        coords.extend(polygon[0])\n",
    "\n",
    "            self.study_area = ee.Geometry.Polygon(coords)\n",
    "            self.study_area_buffered = self.study_area.buffer(5000)\n",
    "            \n",
    "            print(f\"Study area loaded successfully!\")\n",
    "            print(f\"Area: {self.study_area.area().divide(1000000).getInfo():.2f} km²\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading study area: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_landsat_collection(self, year):\n",
    "        \"\"\"\n",
    "        Get appropriate Landsat collection based on year.\n",
    "        \n",
    "        Args:\n",
    "            year (int): Target year\n",
    "            \n",
    "        Returns:\n",
    "            dict: Collection ID and band names\n",
    "        \"\"\"\n",
    "        if year <= 2011:\n",
    "            collection = 'LANDSAT/LT05/C02/T1_L2'\n",
    "            bands = ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']\n",
    "        else:\n",
    "            collection = 'LANDSAT/LC08/C02/T1_L2'\n",
    "            bands = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']\n",
    "        return {'collection': collection, 'bands': bands}\n",
    "    \n",
    "    def scale_landsat(self, image, landsat_type):\n",
    "        \"\"\"\n",
    "        Apply scaling factors to Landsat Collection 2 Level 2 surface reflectance.\n",
    "        \n",
    "        Args:\n",
    "            image: Earth Engine image\n",
    "            landsat_type (str): Landsat sensor type identifier\n",
    "            \n",
    "        Returns:\n",
    "            ee.Image: Scaled image\n",
    "        \"\"\"\n",
    "        if landsat_type in ['LT05']:\n",
    "            optical_bands = image.select(\n",
    "                ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']\n",
    "            ).multiply(0.0000275).add(-0.2)\n",
    "        else:\n",
    "            optical_bands = image.select(\n",
    "                ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']\n",
    "            ).multiply(0.0000275).add(-0.2)\n",
    "        return image.addBands(optical_bands, None, True)\n",
    "    \n",
    "    def create_composite(self, year):\n",
    "        \"\"\"\n",
    "        Create annual median composite for a specific year.\n",
    "        \n",
    "        Args:\n",
    "            year (int): Target year\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (composite image, configuration dict) or (None, config) if no images\n",
    "        \"\"\"\n",
    "        config = self.get_landsat_collection(year)\n",
    "        start_date = self.target_configs[year]['start_date']\n",
    "        end_date = self.target_configs[year]['end_date']\n",
    "        \n",
    "        print(f\"Processing {year} using {config['collection']}\")\n",
    "        print(f\"Date range: {start_date} to {end_date}\")\n",
    "        print(f\"Cloud cover threshold: {self.cloud_threshold}%\")\n",
    "        \n",
    "        collection = ee.ImageCollection(config['collection']) \\\n",
    "            .filterBounds(self.study_area_buffered) \\\n",
    "            .filterDate(start_date, end_date) \\\n",
    "            .filter(ee.Filter.lt('CLOUD_COVER', self.cloud_threshold))\n",
    "        \n",
    "        count = collection.size().getInfo()\n",
    "        print(f\"Found {count} images for {year}\")\n",
    "        \n",
    "        if count == 0:\n",
    "            print(f\"Warning: No images found for {year}. Try adjusting settings.\")\n",
    "            return None, config\n",
    "        \n",
    "        def process_image(image):\n",
    "            scaled = self.scale_landsat(image, config['collection'].split('/')[1])\n",
    "            return scaled\n",
    "        \n",
    "        processed_collection = collection.map(process_image)\n",
    "        composite = processed_collection.median().clip(self.study_area).select(config['bands'])\n",
    "        \n",
    "        composite = composite.set({\n",
    "            'year': year,\n",
    "            'system:time_start': ee.Date(start_date).millis(),\n",
    "            'composite_type': 'median',\n",
    "            'date_range': f\"{start_date}_to_{end_date}\",\n",
    "            'cloud_threshold': self.cloud_threshold,\n",
    "            'image_count': count\n",
    "        })\n",
    "        \n",
    "        return composite, config\n",
    "\n",
    "    def initialize_map(self):\n",
    "        \"\"\"\n",
    "        Initialize geemap Map centered on study area.\n",
    "        \n",
    "        Returns:\n",
    "            geemap.Map: Interactive map instance\n",
    "        \"\"\"\n",
    "        centroid = self.study_area.centroid().coordinates().getInfo()\n",
    "        self.map = geemap.Map(center=[centroid[1], centroid[0]], zoom=8)\n",
    "        self.map.addLayer(\n",
    "            self.study_area, \n",
    "            {'color': 'red', 'fillColor': '00000000', 'width': 2}, \n",
    "            'GKE Boundary'\n",
    "        )\n",
    "        return self.map\n",
    "    \n",
    "    def visualize_composites(self):\n",
    "        \"\"\"\n",
    "        Create and visualize composites for all target years.\n",
    "        \n",
    "        Returns:\n",
    "            geemap.Map: Map with all composite layers added\n",
    "        \"\"\"\n",
    "        if self.map is None:\n",
    "            self.initialize_map()\n",
    "            \n",
    "        self.composites = {}\n",
    "        self.configs = {}\n",
    "        vis_params = {'min': 0.0, 'max': 0.3, 'gamma': 1.4}\n",
    "        \n",
    "        for year in self.target_configs.keys():\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Processing year: {year}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            try:\n",
    "                composite, config = self.create_composite(year)\n",
    "                if composite is not None:\n",
    "                    self.composites[year] = composite\n",
    "                    self.configs[year] = config\n",
    "                    self.map.addLayer(\n",
    "                        composite.select(config['bands'][0:3]),\n",
    "                        vis_params,\n",
    "                        f'{year} Composite',\n",
    "                        False\n",
    "                    )\n",
    "                    print(f\"✓ Successfully processed {year}\")\n",
    "                else:\n",
    "                    print(f\"✗ Failed to process {year}\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error processing {year}: {e}\")\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Visualization complete!\")\n",
    "        print(f\"Processed {len(self.composites)} out of {len(self.target_configs)} years\")\n",
    "        \n",
    "        return self.map\n",
    "    \n",
    "    def save_processor_state(self):\n",
    "        \"\"\"\n",
    "        Save the processor state for export script.\n",
    "        \n",
    "        Returns:\n",
    "            str: Path to saved state file\n",
    "        \"\"\"\n",
    "        processor_state = {\n",
    "            'shapefile_path': self.shapefile_path,\n",
    "            'output_folder': self.output_folder,\n",
    "            'target_configs': self.target_configs,\n",
    "            'cloud_threshold': self.cloud_threshold,\n",
    "            'study_area_coords': self.study_area.coordinates().getInfo() if self.study_area else None,\n",
    "            'configs': self.configs if hasattr(self, 'configs') else {}\n",
    "        }\n",
    "        \n",
    "        state_file = os.path.join(self.output_folder, 'processor_state.pkl')\n",
    "        with open(state_file, 'wb') as f:\n",
    "            pickle.dump(processor_state, f)\n",
    "        \n",
    "        print(f\"\\nProcessor state saved to: {state_file}\")\n",
    "        return state_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48c5662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LANDSAT EXPORT CLASS\n",
    "# =============================================================================\n",
    "\n",
    "class GKELandsatExporter:\n",
    "    \"\"\"\n",
    "    Export processed Landsat composites to Google Drive.\n",
    "    \n",
    "    This class handles:\n",
    "        - Loading processor state from visualization workflow\n",
    "        - Recreating composites for export\n",
    "        - Batch export to Google Drive\n",
    "        - Export progress monitoring\n",
    "    \n",
    "    Attributes:\n",
    "        shapefile_path (str): Path to GKE boundary shapefile\n",
    "        output_folder (str): Local output folder\n",
    "        cloud_threshold (int): Cloud cover threshold used\n",
    "        study_area: Earth Engine geometry\n",
    "        composites (dict): Recreated composites\n",
    "        configs (dict): Configuration metadata\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, processor_state_file):\n",
    "        \"\"\"\n",
    "        Initialize the exporter from saved processor state.\n",
    "        \n",
    "        Args:\n",
    "            processor_state_file (str): Path to processor state pickle file\n",
    "        \"\"\"\n",
    "        self.load_processor_state(processor_state_file)\n",
    "        self.recreate_composites()\n",
    "        \n",
    "    def load_processor_state(self, state_file):\n",
    "        \"\"\"\n",
    "        Load processor state from pickle file.\n",
    "        \n",
    "        Args:\n",
    "            state_file (str): Path to state file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(state_file, 'rb') as f:\n",
    "                state = pickle.load(f)\n",
    "\n",
    "            self.shapefile_path = state['shapefile_path']\n",
    "            self.output_folder = state['output_folder']\n",
    "            self.cloud_threshold = state['cloud_threshold']\n",
    "            self.configs = state.get('configs', {})\n",
    "            self.target_configs = state.get('target_configs', {\n",
    "                1984: {'start_date': '1984-05-01', 'end_date': '1984-08-31'},\n",
    "                1994: {'start_date': '1994-05-01', 'end_date': '1994-08-31'},\n",
    "                2004: {'start_date': '2004-05-01', 'end_date': '2004-08-31'},\n",
    "                2014: {'start_date': '2014-05-01', 'end_date': '2014-08-31'},\n",
    "                2024: {'start_date': '2024-05-01', 'end_date': '2024-08-31'}\n",
    "            })\n",
    "            \n",
    "            if state['study_area_coords']:\n",
    "                self.study_area = ee.Geometry.Polygon(state['study_area_coords'])\n",
    "                self.study_area_buffered = self.study_area.buffer(20000)\n",
    "            else:\n",
    "                raise Exception(\"No study area coordinates found in state file\")\n",
    "            \n",
    "            print(\"✓ Processor state loaded successfully!\")\n",
    "            print(f\"Area: {self.study_area.area().divide(1000000).getInfo():.2f} km²\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading processor state: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def get_landsat_collection(self, year):\n",
    "        \"\"\"Get appropriate Landsat collection based on year.\"\"\"\n",
    "        if year <= 2011:\n",
    "            collection = 'LANDSAT/LT05/C02/T1_L2'\n",
    "            bands = ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']\n",
    "        else:\n",
    "            collection = 'LANDSAT/LC08/C02/T1_L2'\n",
    "            bands = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']\n",
    "        return {'collection': collection, 'bands': bands}\n",
    "    \n",
    "    def scale_landsat(self, image, landsat_type):\n",
    "        \"\"\"Scale Landsat surface reflectance values.\"\"\"\n",
    "        if landsat_type in ['LT05']:\n",
    "            optical_bands = image.select(\n",
    "                ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']\n",
    "            ).multiply(0.0000275).add(-0.2)\n",
    "        else:\n",
    "            optical_bands = image.select(\n",
    "                ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']\n",
    "            ).multiply(0.0000275).add(-0.2)\n",
    "        return image.addBands(optical_bands, None, True)\n",
    "    \n",
    "    def create_composite(self, year):\n",
    "        \"\"\"Recreate composite for export.\"\"\"\n",
    "        config = self.get_landsat_collection(year)\n",
    "        start_date = self.target_configs[year]['start_date']\n",
    "        end_date = self.target_configs[year]['end_date']\n",
    "        \n",
    "        print(f\"Recreating composite for {year}...\")\n",
    "        print(f\"Date range: {start_date} to {end_date}\")\n",
    "        print(f\"Cloud cover threshold: {self.cloud_threshold}%\")\n",
    "        \n",
    "        collection = ee.ImageCollection(config['collection']) \\\n",
    "            .filterBounds(self.study_area_buffered) \\\n",
    "            .filterDate(start_date, end_date) \\\n",
    "            .filter(ee.Filter.lt('CLOUD_COVER', self.cloud_threshold))\n",
    "        \n",
    "        count = collection.size().getInfo()\n",
    "        print(f\"Found {count} images for {year}\")\n",
    "        \n",
    "        if count == 0:\n",
    "            print(f\"Warning: No images found for {year}.\")\n",
    "            return None, config\n",
    "        \n",
    "        def process_image(image):\n",
    "            scaled = self.scale_landsat(image, config['collection'].split('/')[1])\n",
    "            return scaled\n",
    "        \n",
    "        processed_collection = collection.map(process_image)\n",
    "        composite = processed_collection.median().clip(self.study_area).select(config['bands'])\n",
    "        \n",
    "        composite = composite.set({\n",
    "            'year': year,\n",
    "            'system:time_start': ee.Date(start_date).millis(),\n",
    "            'composite_type': 'median',\n",
    "            'date_range': f\"{start_date}_to_{end_date}\",\n",
    "            'cloud_threshold': self.cloud_threshold,\n",
    "            'image_count': count\n",
    "        })\n",
    "        \n",
    "        return composite, config\n",
    "    \n",
    "    def recreate_composites(self):\n",
    "        \"\"\"Recreate all composites for export.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"RECREATING COMPOSITES FOR EXPORT\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        self.composites = {}\n",
    "        self.configs = {}\n",
    "        \n",
    "        for year in self.target_configs.keys():\n",
    "            try:\n",
    "                composite, config = self.create_composite(year)\n",
    "                if composite is not None:\n",
    "                    self.composites[year] = composite\n",
    "                    self.configs[year] = config\n",
    "                    print(f\"✓ Composite recreated for {year}\")\n",
    "                else:\n",
    "                    print(f\"✗ Failed to recreate composite for {year}\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error recreating {year}: {e}\")\n",
    "        \n",
    "        print(f\"\\nRecreated {len(self.composites)} composites for export\")\n",
    "    \n",
    "    def export_composite(self, year, composite, config):\n",
    "        \"\"\"\n",
    "        Export a single composite to Google Drive.\n",
    "        \n",
    "        Args:\n",
    "            year (int): Target year\n",
    "            composite: Earth Engine image\n",
    "            config (dict): Configuration metadata\n",
    "            \n",
    "        Returns:\n",
    "            ee.batch.Task: Export task\n",
    "        \"\"\"\n",
    "        export_image = composite.select(config['bands'])\n",
    "        description = f'GKE_Composite_{year}'\n",
    "        \n",
    "        export_params = {\n",
    "            'image': export_image,\n",
    "            'description': description,\n",
    "            'folder': 'GKE_Landsat_Data',\n",
    "            'region': self.study_area,\n",
    "            'scale': 30,\n",
    "            'crs': 'EPSG:32735',\n",
    "            'maxPixels': 1e9,\n",
    "            'fileFormat': 'GeoTIFF'\n",
    "        }\n",
    "\n",
    "        task = ee.batch.Export.image.toDrive(**export_params)\n",
    "        task.start()\n",
    "        print(f\"Started export for {year} Composite - Task ID: {task.id}\")\n",
    "        return task\n",
    "    \n",
    "    def export_all_composites(self):\n",
    "        \"\"\"\n",
    "        Export all processed composites.\n",
    "        \n",
    "        Returns:\n",
    "            dict: Export tasks keyed by year\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'composites') or not self.composites:\n",
    "            print(\"No composites available for export.\")\n",
    "            return {}\n",
    "        \n",
    "        export_tasks = {}\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"STARTING EXPORTS TO GOOGLE DRIVE\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        for year in self.composites.keys():\n",
    "            try:\n",
    "                composite = self.composites[year]\n",
    "                config = self.configs[year]\n",
    "                task = self.export_composite(year, composite, config)\n",
    "                export_tasks[f\"{year}_composite\"] = task\n",
    "                print(f\"✓ Export started for {year}\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Export failed for {year}: {e}\")\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"EXPORT SUMMARY\")\n",
    "        print(f\"Total exports started: {len(export_tasks)}\")\n",
    "        print(f\"Google Drive folder: 'GKE_Landsat_Data'\")\n",
    "        \n",
    "        return export_tasks\n",
    "    \n",
    "    def monitor_exports(self, export_tasks):\n",
    "        \"\"\"\n",
    "        Monitor export progress with periodic status updates.\n",
    "        \n",
    "        Args:\n",
    "            export_tasks (dict): Export tasks to monitor\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"MONITORING EXPORTS\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        while True:\n",
    "            completed = 0\n",
    "            failed = 0\n",
    "            running = 0\n",
    "            \n",
    "            print(f\"\\nStatus check at {datetime.now().strftime('%H:%M:%S')}:\")\n",
    "            \n",
    "            for key, task in export_tasks.items():\n",
    "                status = task.status()\n",
    "                state = status['state']\n",
    "                \n",
    "                if state == 'COMPLETED':\n",
    "                    completed += 1\n",
    "                    print(f\"  ✓ {key}: COMPLETED\")\n",
    "                elif state == 'FAILED':\n",
    "                    failed += 1\n",
    "                    error_msg = status.get('error_message', 'Unknown error')\n",
    "                    print(f\"  ✗ {key}: FAILED - {error_msg}\")\n",
    "                elif state in ['RUNNING', 'READY']:\n",
    "                    running += 1\n",
    "                    progress = status.get('progress', 0)\n",
    "                    print(f\"  ⏳ {key}: {state} ({progress:.1f}%)\")\n",
    "                else:\n",
    "                    print(f\"  ? {key}: {state}\")\n",
    "            \n",
    "            print(f\"\\nSummary: {completed} completed, {running} running, {failed} failed\")\n",
    "            \n",
    "            if completed + failed == len(export_tasks):\n",
    "                print(f\"\\n{'='*50}\")\n",
    "                print(f\"ALL EXPORTS COMPLETED!\")\n",
    "                print(f\"✓ {completed} successful\")\n",
    "                print(f\"✗ {failed} failed\")\n",
    "                print(f\"Check your Google Drive 'GKE_Landsat_Data' folder\")\n",
    "                break\n",
    "            \n",
    "            time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ff6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MAIN WORKFLOW FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def main_visualization_workflow(shapefile_path, output_folder, cloud_threshold=20):\n",
    "    \"\"\"\n",
    "    Main workflow for GKE Landsat visualization.\n",
    "    \n",
    "    Args:\n",
    "        shapefile_path (str): Path to study area shapefile\n",
    "        output_folder (str): Output directory\n",
    "        cloud_threshold (int): Maximum cloud cover percentage\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (processor instance, map widget)\n",
    "    \"\"\"\n",
    "    print(f\"\"\"\n",
    "    {'='*70}\n",
    "    GKE LANDSAT VISUALIZATION\n",
    "    {'='*70}\n",
    "    Research: Habitat Loss Analysis (1984-2024)\n",
    "    Study Area: {shapefile_path}\n",
    "    Output Folder: {output_folder}\n",
    "    Cloud Threshold: {cloud_threshold}%\n",
    "    {'='*70}\n",
    "    \"\"\")\n",
    "    \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    processor = GKELandsatVisualization(shapefile_path, output_folder, cloud_threshold)\n",
    "    \n",
    "    print(\"STEP 1: Loading study area...\")\n",
    "    if not processor.load_study_area():\n",
    "        print(\"Failed to load study area. Exiting.\")\n",
    "        return None\n",
    "    \n",
    "    print(\"\\nSTEP 2: Processing and visualizing composites...\")\n",
    "    map_widget = processor.visualize_composites()\n",
    "    \n",
    "    print(\"\\nSTEP 3: Saving processor state...\")\n",
    "    state_file = processor.save_processor_state()\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"VISUALIZATION COMPLETE!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    return processor, map_widget\n",
    "\n",
    "\n",
    "def main_export_workflow(output_folder, monitor_progress=True):\n",
    "    \"\"\"\n",
    "    Main workflow for exporting GKE Landsat data.\n",
    "    \n",
    "    Args:\n",
    "        output_folder (str): Output directory containing processor state\n",
    "        monitor_progress (bool): Whether to monitor export progress\n",
    "        \n",
    "    Returns:\n",
    "        dict: Export tasks\n",
    "    \"\"\"\n",
    "    print(f\"\"\"\n",
    "    {'='*70}\n",
    "    GKE LANDSAT EXPORT\n",
    "    {'='*70}\n",
    "    Research: Habitat Loss Analysis (1984-2024)\n",
    "    Output Folder: {output_folder}\n",
    "    Target: Google Drive 'GKE_Landsat_Data' folder\n",
    "    {'='*70}\n",
    "    \"\"\")\n",
    "\n",
    "    state_file = os.path.join(output_folder, 'processor_state.pkl')\n",
    "    if not os.path.exists(state_file):\n",
    "        print(f\"ERROR: Processor state file not found at {state_file}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        print(\"STEP 1: Loading processor state...\")\n",
    "        exporter = GKELandsatExporter(state_file)\n",
    "\n",
    "        print(\"\\nSTEP 2: Starting exports...\")\n",
    "        export_tasks = exporter.export_all_composites()\n",
    "        \n",
    "        if not export_tasks:\n",
    "            print(\"No export tasks created. Exiting.\")\n",
    "            return None\n",
    "        \n",
    "        if monitor_progress:\n",
    "            print(\"\\nSTEP 3: Monitoring export progress...\")\n",
    "            exporter.monitor_exports(export_tasks)\n",
    "        else:\n",
    "            print(\"\\nSTEP 3: Export monitoring skipped.\")\n",
    "            print(\"\\nTask IDs for manual monitoring:\")\n",
    "            for key, task in export_tasks.items():\n",
    "                print(f\"  {key}: {task.id}\")\n",
    "        \n",
    "        return export_tasks\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Export workflow failed: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3f5433",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize Earth Engine\n",
    "    try:\n",
    "        ee.Initialize()\n",
    "        print(\"Earth Engine initialized successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing Earth Engine: {e}\")\n",
    "        print(\"Please authenticate with: ee.Authenticate()\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Configuration - update these paths\n",
    "    SHAPEFILE_PATH = r\"D:/Publication/Habitat Loss in the Greater Kafue Ecosystem/Thesis_anlysis/Sable/data/vectors/GKE_Boundary.shp\"\n",
    "    OUTPUT_FOLDER = r\"D:/Publication/Habitat Loss in the Greater Kafue Ecosystem/Thesis_anlysis/Finale/outputs\"\n",
    "    CLOUD_THRESHOLD = 5\n",
    "    \n",
    "    if not os.path.exists(SHAPEFILE_PATH):\n",
    "        print(f\"ERROR: Shapefile not found at {SHAPEFILE_PATH}\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Run visualization workflow\n",
    "    processor, map_widget = main_visualization_workflow(\n",
    "        SHAPEFILE_PATH, \n",
    "        OUTPUT_FOLDER, \n",
    "        cloud_threshold=CLOUD_THRESHOLD\n",
    "    )\n",
    "    \n",
    "    if processor is not None and map_widget is not None:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"MAP READY FOR DISPLAY\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(\"In Jupyter notebook, display with: map_widget\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792bf64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_widget"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
