{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184b94bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "GKE Habitat Analysis - Objective A\n",
    "================================================================================\n",
    "\n",
    "Historical Habitat Dynamics in the Greater Kafue Ecosystem (1984-2024)\n",
    "\n",
    "This module performs comprehensive habitat change analysis including:\n",
    "    1. Land Cover Area Statistics by Management Zone\n",
    "    2. Change Detection and Transition Matrices\n",
    "    3. KNP Boundary Gradient Analysis\n",
    "    4. GMA Centroid Gradient Analysis\n",
    "    5. Road Proximity Analysis\n",
    "\n",
    "Author: Gift Mulenga\n",
    "Institution: Copperbelt University, Zambia\n",
    "Research: MSc Thesis - Tropical Ecology\n",
    "\n",
    "Requirements:\n",
    "    - rasterio\n",
    "    - geopandas\n",
    "    - pandas\n",
    "    - numpy\n",
    "    - matplotlib\n",
    "    - scipy\n",
    "    - shapely\n",
    "\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.warp import reproject, Resampling\n",
    "from shapely.geometry import mapping, Point\n",
    "from shapely.ops import unary_union\n",
    "from shapely.validation import make_valid\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ecdf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install rasterio geopandas pandas numpy matplotlib scipy shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a815264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration parameters for the GKE habitat analysis.\"\"\"\n",
    "    \n",
    "    # Land Cover Classification Scheme (6 Classes)\n",
    "    CLASS_LABELS = {\n",
    "        1: \"Built-up\",\n",
    "        2: \"Forest\",\n",
    "        3: \"Cropland\",\n",
    "        4: \"Grassland\",\n",
    "        5: \"Bareland\",\n",
    "        6: \"Water\"\n",
    "    }\n",
    "    \n",
    "    CLASS_COLORS = {\n",
    "        1: \"#FF0000\",  # Red - Built-up\n",
    "        2: \"#008000\",  # Green - Forest\n",
    "        3: \"#FFFF00\",  # Yellow - Cropland\n",
    "        4: \"#90EE90\",  # Light Green - Grassland\n",
    "        5: \"#FFB347\",  # Peach - Bareland\n",
    "        6: \"#0000FF\",  # Blue - Water\n",
    "    }\n",
    "    \n",
    "    # Habitat classification\n",
    "    NATURAL_HABITAT_CLASSES = [2, 4, 6]  # Forest, Grassland, Water\n",
    "    DISTURBED_CLASSES = [1, 3, 5]  # Built-up, Cropland, Bareland\n",
    "    FOREST_CLASSES = [2]\n",
    "    \n",
    "    # Spatial resolution\n",
    "    CELL_SIZE = 30  # meters (Landsat resolution)\n",
    "    PIXEL_TO_HA = (CELL_SIZE * CELL_SIZE) / 10000  # 0.09 ha per pixel\n",
    "    \n",
    "    # Coordinate Reference System\n",
    "    CRS_EPSG = 32735  # UTM Zone 35S\n",
    "    \n",
    "    # Time points\n",
    "    YEARS = [1984, 1994, 2004, 2014, 2024]\n",
    "    \n",
    "    # Gradient analysis parameters\n",
    "    KNP_BUFFER_INCREMENT = 200  # meters\n",
    "    KNP_MAX_BUFFER_DISTANCE = 15000  # meters (15 km)\n",
    "    GMA_BUFFER_INCREMENT = 200  # meters\n",
    "    GMA_MAX_BUFFER_DISTANCE = 10000  # meters (10 km)\n",
    "    ROAD_BUFFER_INCREMENT = 200  # meters\n",
    "    ROAD_MAX_BUFFER_DISTANCE = 10000  # meters (10 km)\n",
    "    \n",
    "    # Road classification mapping\n",
    "    ROAD_CLASS_MAPPING = {\n",
    "        \"primary\": \"Primary\",\n",
    "        \"trunk\": \"Primary\",\n",
    "        \"secondary\": \"Secondary\",\n",
    "        \"tertiary\": \"Tertiary\",\n",
    "        \"residential\": \"Tertiary\",\n",
    "        \"unclassified\": \"Tertiary\",\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24846e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GEOMETRY HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def fix_geometry(gdf):\n",
    "    \"\"\"\n",
    "    Fix invalid geometries in a GeoDataFrame.\n",
    "    \n",
    "    Args:\n",
    "        gdf (GeoDataFrame): Input GeoDataFrame with potentially invalid geometries\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (Fixed GeoDataFrame, Number of fixes applied)\n",
    "    \"\"\"\n",
    "    fixes_count = 0\n",
    "    \n",
    "    # Remove null geometries\n",
    "    null_mask = gdf.geometry.isna()\n",
    "    if null_mask.any():\n",
    "        fixes_count += null_mask.sum()\n",
    "        gdf = gdf[~null_mask].copy()\n",
    "    \n",
    "    # Fix invalid geometries using buffer(0) method\n",
    "    invalid_mask = ~gdf.geometry.is_valid\n",
    "    if invalid_mask.any():\n",
    "        fixes_count += invalid_mask.sum()\n",
    "        gdf.loc[invalid_mask, 'geometry'] = gdf.loc[invalid_mask, 'geometry'].buffer(0)\n",
    "        \n",
    "        # Apply make_valid for any still invalid\n",
    "        still_invalid = ~gdf.geometry.is_valid\n",
    "        if still_invalid.any():\n",
    "            gdf.loc[still_invalid, 'geometry'] = gdf.loc[still_invalid, 'geometry'].apply(\n",
    "                lambda geom: make_valid(geom) if not geom.is_valid else geom\n",
    "            )\n",
    "    \n",
    "    # Remove duplicate geometries\n",
    "    duplicate_mask = gdf.geometry.duplicated()\n",
    "    if duplicate_mask.any():\n",
    "        fixes_count += duplicate_mask.sum()\n",
    "        gdf = gdf[~duplicate_mask].copy()\n",
    "    \n",
    "    return gdf, fixes_count\n",
    "\n",
    "\n",
    "def calculate_area_ha(gdf, target_crs_epsg=32735):\n",
    "    \"\"\"\n",
    "    Calculate total area in hectares.\n",
    "    \n",
    "    Args:\n",
    "        gdf (GeoDataFrame): Input GeoDataFrame\n",
    "        target_crs_epsg (int): EPSG code for projected CRS\n",
    "    \n",
    "    Returns:\n",
    "        float: Total area in hectares\n",
    "    \"\"\"\n",
    "    if gdf.crs and gdf.crs.to_epsg() != target_crs_epsg:\n",
    "        gdf = gdf.to_crs(epsg=target_crs_epsg)\n",
    "    elif not gdf.crs:\n",
    "        gdf = gdf.set_crs(epsg=target_crs_epsg)\n",
    "    \n",
    "    return gdf.geometry.area.sum() / 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51025a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# AREA CALCULATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def pixels_to_hectares(pixel_count):\n",
    "    \"\"\"Convert pixel count to hectares.\"\"\"\n",
    "    return pixel_count * Config.PIXEL_TO_HA\n",
    "\n",
    "\n",
    "def load_boundary(path, filter_name=None, name_field=\"NAME\"):\n",
    "    \"\"\"\n",
    "    Load a boundary shapefile and optionally filter by name.\n",
    "    \n",
    "    Args:\n",
    "        path (str): Path to shapefile\n",
    "        filter_name (str): Optional name to filter by\n",
    "        name_field (str): Column name containing feature names\n",
    "        \n",
    "    Returns:\n",
    "        GeoDataFrame: Loaded and filtered boundary\n",
    "    \"\"\"\n",
    "    gdf = gpd.read_file(path)\n",
    "    if gdf.crs.to_epsg() != Config.CRS_EPSG:\n",
    "        gdf = gdf.to_crs(epsg=Config.CRS_EPSG)\n",
    "    if filter_name and name_field in gdf.columns:\n",
    "        gdf = gdf[gdf[name_field].str.contains(filter_name, case=False, na=False)]\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def calculate_class_areas(raster_path, geometry=None):\n",
    "    \"\"\"\n",
    "    Calculate area for each land cover class within a geometry.\n",
    "    \n",
    "    Args:\n",
    "        raster_path (str): Path to the LULC raster\n",
    "        geometry (GeoDataFrame): Optional geometry to mask the raster\n",
    "    \n",
    "    Returns:\n",
    "        dict: {class_value: area_in_hectares}\n",
    "    \"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        if geometry is not None:\n",
    "            geoms = [mapping(geom) for geom in geometry.geometry]\n",
    "            out_image, _ = mask(src, geoms, crop=True, nodata=0)\n",
    "            data = out_image[0]\n",
    "        else:\n",
    "            data = src.read(1)\n",
    "        \n",
    "        unique, counts = np.unique(data[data > 0], return_counts=True)\n",
    "        class_areas = {int(c): pixels_to_hectares(n) for c, n in zip(unique, counts)}\n",
    "        \n",
    "    return class_areas\n",
    "\n",
    "\n",
    "def create_area_table(class_areas_dict, years, class_labels):\n",
    "    \"\"\"\n",
    "    Create a formatted area table from class areas dictionary.\n",
    "    \n",
    "    Args:\n",
    "        class_areas_dict (dict): Areas by year and class\n",
    "        years (list): Years to include\n",
    "        class_labels (dict): Class value to label mapping\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Formatted area table\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for class_val, label in class_labels.items():\n",
    "        row = {\"Land Cover Class\": label}\n",
    "        for year in years:\n",
    "            area = class_areas_dict.get(year, {}).get(class_val, 0)\n",
    "            total = sum(class_areas_dict.get(year, {}).values())\n",
    "            pct = (area / total * 100) if total > 0 else 0\n",
    "            row[f\"{year} Area (ha)\"] = round(area, 2)\n",
    "            row[f\"{year} (%)\"] = round(pct, 2)\n",
    "        data.append(row)\n",
    "    \n",
    "    # Add Total row\n",
    "    total_row = {\"Land Cover Class\": \"Total\"}\n",
    "    for year in years:\n",
    "        total = sum(class_areas_dict.get(year, {}).values())\n",
    "        total_row[f\"{year} Area (ha)\"] = round(total, 2)\n",
    "        total_row[f\"{year} (%)\"] = 100.0\n",
    "    data.append(total_row)\n",
    "    \n",
    "    # Add Natural Habitat row\n",
    "    natural_row = {\"Land Cover Class\": \"Natural Habitat*\"}\n",
    "    for year in years:\n",
    "        natural_area = sum(class_areas_dict.get(year, {}).get(c, 0) \n",
    "                         for c in Config.NATURAL_HABITAT_CLASSES)\n",
    "        total = sum(class_areas_dict.get(year, {}).values())\n",
    "        pct = (natural_area / total * 100) if total > 0 else 0\n",
    "        natural_row[f\"{year} Area (ha)\"] = round(natural_area, 2)\n",
    "        natural_row[f\"{year} (%)\"] = round(pct, 2)\n",
    "    data.append(natural_row)\n",
    "    \n",
    "    # Add Disturbed row\n",
    "    disturbed_row = {\"Land Cover Class\": \"Disturbed†\"}\n",
    "    for year in years:\n",
    "        disturbed_area = sum(class_areas_dict.get(year, {}).get(c, 0) \n",
    "                           for c in Config.DISTURBED_CLASSES)\n",
    "        total = sum(class_areas_dict.get(year, {}).values())\n",
    "        pct = (disturbed_area / total * 100) if total > 0 else 0\n",
    "        disturbed_row[f\"{year} Area (ha)\"] = round(disturbed_area, 2)\n",
    "        disturbed_row[f\"{year} (%)\"] = round(pct, 2)\n",
    "    data.append(disturbed_row)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def analyze_zone(zone_name, geometry, raster_paths, years):\n",
    "    \"\"\"\n",
    "    Analyze land cover composition for a specific zone.\n",
    "    \n",
    "    Args:\n",
    "        zone_name (str): Name of the zone\n",
    "        geometry (GeoDataFrame): Zone boundary\n",
    "        raster_paths (dict): LULC raster paths by year\n",
    "        years (list): Years to analyze\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Land cover composition table\n",
    "    \"\"\"\n",
    "    print(f\"  Analyzing {zone_name}...\")\n",
    "    \n",
    "    class_areas_dict = {}\n",
    "    for year in years:\n",
    "        if year in raster_paths:\n",
    "            areas = calculate_class_areas(raster_paths[year], geometry)\n",
    "            class_areas_dict[year] = areas\n",
    "    \n",
    "    df = create_area_table(class_areas_dict, [y for y in years if y in raster_paths], \n",
    "                          Config.CLASS_LABELS)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2610a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CHANGE DETECTION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_transition_matrix(raster_t1_path, raster_t2_path, geometry=None):\n",
    "    \"\"\"\n",
    "    Calculate transition matrix between two time periods.\n",
    "    \n",
    "    Args:\n",
    "        raster_t1_path (str): Path to time 1 raster\n",
    "        raster_t2_path (str): Path to time 2 raster\n",
    "        geometry (GeoDataFrame): Optional geometry to mask\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Transition matrix with areas in hectares\n",
    "    \"\"\"\n",
    "    with rasterio.open(raster_t1_path) as src_t1:\n",
    "        if geometry is not None:\n",
    "            geoms = [mapping(geom) for geom in geometry.geometry]\n",
    "            data_t1, _ = mask(src_t1, geoms, crop=True, nodata=0)\n",
    "            data_t1 = data_t1[0]\n",
    "        else:\n",
    "            data_t1 = src_t1.read(1)\n",
    "    \n",
    "    with rasterio.open(raster_t2_path) as src_t2:\n",
    "        if geometry is not None:\n",
    "            geoms = [mapping(geom) for geom in geometry.geometry]\n",
    "            data_t2, _ = mask(src_t2, geoms, crop=True, nodata=0)\n",
    "            data_t2 = data_t2[0]\n",
    "        else:\n",
    "            data_t2 = src_t2.read(1)\n",
    "    \n",
    "    # Ensure same shape\n",
    "    if data_t1.shape != data_t2.shape:\n",
    "        min_rows = min(data_t1.shape[0], data_t2.shape[0])\n",
    "        min_cols = min(data_t1.shape[1], data_t2.shape[1])\n",
    "        data_t1 = data_t1[:min_rows, :min_cols]\n",
    "        data_t2 = data_t2[:min_rows, :min_cols]\n",
    "    \n",
    "    # Calculate transitions\n",
    "    classes = list(Config.CLASS_LABELS.keys())\n",
    "    matrix = np.zeros((len(classes), len(classes)))\n",
    "    \n",
    "    for i, class_from in enumerate(classes):\n",
    "        for j, class_to in enumerate(classes):\n",
    "            count = np.sum((data_t1 == class_from) & (data_t2 == class_to))\n",
    "            matrix[i, j] = pixels_to_hectares(count)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(\n",
    "        matrix,\n",
    "        index=[Config.CLASS_LABELS[c] for c in classes],\n",
    "        columns=[Config.CLASS_LABELS[c] for c in classes]\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_net_change(class_areas_dict, years):\n",
    "    \"\"\"\n",
    "    Calculate net change in area for each class between years.\n",
    "    \n",
    "    Args:\n",
    "        class_areas_dict (dict): Areas by year and class\n",
    "        years (list): Years to analyze\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Net change summary\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for class_val, label in Config.CLASS_LABELS.items():\n",
    "        row = {\"Land Cover Class\": label}\n",
    "        \n",
    "        for i in range(len(years) - 1):\n",
    "            y1, y2 = years[i], years[i+1]\n",
    "            area_t1 = class_areas_dict.get(y1, {}).get(class_val, 0)\n",
    "            area_t2 = class_areas_dict.get(y2, {}).get(class_val, 0)\n",
    "            change = area_t2 - area_t1\n",
    "            pct_change = (change / area_t1 * 100) if area_t1 > 0 else 0\n",
    "            \n",
    "            row[f\"{y1}-{y2} Change (ha)\"] = round(change, 2)\n",
    "            row[f\"{y1}-{y2} Change (%)\"] = round(pct_change, 2)\n",
    "        \n",
    "        # Total change\n",
    "        first_area = class_areas_dict.get(years[0], {}).get(class_val, 0)\n",
    "        last_area = class_areas_dict.get(years[-1], {}).get(class_val, 0)\n",
    "        total_change = last_area - first_area\n",
    "        total_pct = (total_change / first_area * 100) if first_area > 0 else 0\n",
    "        \n",
    "        row[f\"{years[0]}-{years[-1]} Total (ha)\"] = round(total_change, 2)\n",
    "        row[f\"{years[0]}-{years[-1]} Total (%)\"] = round(total_pct, 2)\n",
    "        \n",
    "        data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GRADIENT ANALYSIS FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def create_distance_raster(boundary_gdf, reference_raster_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Create a distance raster from a boundary.\n",
    "    \n",
    "    Args:\n",
    "        boundary_gdf (GeoDataFrame): Boundary geometry\n",
    "        reference_raster_path (str): Reference raster for extent/resolution\n",
    "        output_path (str): Optional path to save raster\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (distance array, profile)\n",
    "    \"\"\"\n",
    "    with rasterio.open(reference_raster_path) as src:\n",
    "        profile = src.profile.copy()\n",
    "        transform = src.transform\n",
    "        shape = (src.height, src.width)\n",
    "    \n",
    "    # Rasterize boundary\n",
    "    boundary_raster = rasterize(\n",
    "        [(geom, 1) for geom in boundary_gdf.geometry],\n",
    "        out_shape=shape,\n",
    "        transform=transform,\n",
    "        fill=0,\n",
    "        dtype=np.uint8\n",
    "    )\n",
    "    \n",
    "    # Calculate distance\n",
    "    distance = distance_transform_edt(boundary_raster == 0)\n",
    "    distance = distance * profile['transform'][0]  # Convert to meters\n",
    "    \n",
    "    if output_path:\n",
    "        profile.update(dtype=np.float32, count=1)\n",
    "        with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "            dst.write(distance.astype(np.float32), 1)\n",
    "    \n",
    "    return distance, profile\n",
    "\n",
    "\n",
    "def analyze_gradient(lulc_raster_path, distance_raster, max_distance, increment):\n",
    "    \"\"\"\n",
    "    Analyze land cover composition at different distances from a boundary.\n",
    "    \n",
    "    Args:\n",
    "        lulc_raster_path (str): Path to LULC raster\n",
    "        distance_raster (ndarray): Distance values\n",
    "        max_distance (int): Maximum distance to analyze\n",
    "        increment (int): Distance increment\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Gradient analysis results\n",
    "    \"\"\"\n",
    "    with rasterio.open(lulc_raster_path) as src:\n",
    "        lulc = src.read(1)\n",
    "    \n",
    "    # Ensure same shape\n",
    "    if lulc.shape != distance_raster.shape:\n",
    "        min_rows = min(lulc.shape[0], distance_raster.shape[0])\n",
    "        min_cols = min(lulc.shape[1], distance_raster.shape[1])\n",
    "        lulc = lulc[:min_rows, :min_cols]\n",
    "        distance_raster = distance_raster[:min_rows, :min_cols]\n",
    "    \n",
    "    results = []\n",
    "    distances = list(range(0, max_distance + increment, increment))\n",
    "    \n",
    "    for dist in distances:\n",
    "        # Create distance band mask\n",
    "        if dist == 0:\n",
    "            band_mask = distance_raster <= increment\n",
    "        else:\n",
    "            band_mask = (distance_raster > dist) & (distance_raster <= dist + increment)\n",
    "        \n",
    "        band_data = lulc[band_mask]\n",
    "        total_pixels = len(band_data[band_data > 0])\n",
    "        \n",
    "        if total_pixels == 0:\n",
    "            continue\n",
    "        \n",
    "        row = {\"Distance_m\": dist + increment}\n",
    "        \n",
    "        # Calculate percentage for each class\n",
    "        for class_val, label in Config.CLASS_LABELS.items():\n",
    "            count = np.sum(band_data == class_val)\n",
    "            pct = (count / total_pixels * 100) if total_pixels > 0 else 0\n",
    "            row[f\"{label}_%\"] = round(pct, 2)\n",
    "        \n",
    "        # Calculate aggregated categories\n",
    "        natural_count = sum(np.sum(band_data == c) for c in Config.NATURAL_HABITAT_CLASSES)\n",
    "        disturbed_count = sum(np.sum(band_data == c) for c in Config.DISTURBED_CLASSES)\n",
    "        forest_count = sum(np.sum(band_data == c) for c in Config.FOREST_CLASSES)\n",
    "        \n",
    "        row[\"Natural_Habitat_%\"] = round(natural_count / total_pixels * 100, 2)\n",
    "        row[\"Disturbed_%\"] = round(disturbed_count / total_pixels * 100, 2)\n",
    "        row[\"Forest_%\"] = round(forest_count / total_pixels * 100, 2)\n",
    "        row[\"Total_Pixels\"] = total_pixels\n",
    "        \n",
    "        results.append(row)\n",
    "    \n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2628bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def plot_temporal_trends(class_trends, years, output_path):\n",
    "    \"\"\"\n",
    "    Create temporal trend line plot for land cover classes.\n",
    "    \n",
    "    Args:\n",
    "        class_trends (dict): Trends by class\n",
    "        years (list): Years\n",
    "        output_path (str): Output file path\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    \n",
    "    for class_val, label in Config.CLASS_LABELS.items():\n",
    "        if label in class_trends:\n",
    "            ax.plot(years, class_trends[label], \n",
    "                   marker='o', linewidth=2.5, markersize=8,\n",
    "                   color=Config.CLASS_COLORS[class_val], label=label)\n",
    "    \n",
    "    ax.set_xlabel(\"Year\", fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(\"Coverage (%)\", fontsize=12, fontweight='bold')\n",
    "    ax.set_title(\"Temporal Trends in Land Cover Composition\", \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.legend(title=\"Land Cover Class\", fontsize=10, loc='best')\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "    ax.set_xticks(years)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Saved: {os.path.basename(output_path)}\")\n",
    "\n",
    "\n",
    "def plot_gradient_analysis(gradient_df, output_path, title=\"Gradient Analysis\"):\n",
    "    \"\"\"\n",
    "    Create gradient analysis visualization.\n",
    "    \n",
    "    Args:\n",
    "        gradient_df (DataFrame): Gradient analysis results\n",
    "        output_path (str): Output file path\n",
    "        title (str): Plot title\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    \n",
    "    # Plot 1: All individual classes\n",
    "    for class_val, label in Config.CLASS_LABELS.items():\n",
    "        col_name = f\"{label}_%\"\n",
    "        if col_name in gradient_df.columns:\n",
    "            ax1.plot(gradient_df[\"Distance_m\"], gradient_df[col_name], \n",
    "                    marker='o', linewidth=2, label=label,\n",
    "                    color=Config.CLASS_COLORS[class_val])\n",
    "    \n",
    "    ax1.set_xlabel(\"Distance (m)\", fontsize=11, fontweight='bold')\n",
    "    ax1.set_ylabel(\"Coverage (%)\", fontsize=11, fontweight='bold')\n",
    "    ax1.set_title(f\"{title} - Individual Classes\", fontsize=12, fontweight='bold')\n",
    "    ax1.legend(fontsize=9, loc='best')\n",
    "    ax1.grid(True, linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Plot 2: Aggregated categories\n",
    "    ax2.plot(gradient_df[\"Distance_m\"], gradient_df[\"Natural_Habitat_%\"], \n",
    "            marker='o', linewidth=3, label='Natural Habitat', color='#006400')\n",
    "    ax2.plot(gradient_df[\"Distance_m\"], gradient_df[\"Disturbed_%\"], \n",
    "            marker='s', linewidth=3, label='Disturbed', color='#8B0000')\n",
    "    ax2.plot(gradient_df[\"Distance_m\"], gradient_df[\"Forest_%\"], \n",
    "            marker='^', linewidth=2, label='Forest', color='#228B22')\n",
    "    \n",
    "    ax2.set_xlabel(\"Distance (m)\", fontsize=11, fontweight='bold')\n",
    "    ax2.set_ylabel(\"Coverage (%)\", fontsize=11, fontweight='bold')\n",
    "    ax2.set_title(f\"{title} - Aggregated Categories\", fontsize=12, fontweight='bold')\n",
    "    ax2.legend(fontsize=10, loc='best')\n",
    "    ax2.grid(True, linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Saved: {os.path.basename(output_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# OUTPUT HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def get_output_path(output_dir, filename, subdir=\"tables\"):\n",
    "    \"\"\"\n",
    "    Get full output path for a file.\n",
    "    \n",
    "    Args:\n",
    "        output_dir (str): Base output directory\n",
    "        filename (str): File name\n",
    "        subdir (str): Subdirectory (tables, figures, rasters)\n",
    "        \n",
    "    Returns:\n",
    "        str: Full output path\n",
    "    \"\"\"\n",
    "    full_dir = os.path.join(output_dir, subdir)\n",
    "    os.makedirs(full_dir, exist_ok=True)\n",
    "    return os.path.join(full_dir, filename)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN ANALYSIS WORKFLOW\n",
    "# =============================================================================\n",
    "\n",
    "def run_objective_a_analysis(data_dir, output_dir, lulc_rasters, boundaries):\n",
    "    \"\"\"\n",
    "    Run complete Objective A analysis.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str): Input data directory\n",
    "        output_dir (str): Output directory\n",
    "        lulc_rasters (dict): LULC raster paths by year\n",
    "        boundaries (dict): Boundary shapefile paths\n",
    "        \n",
    "    Returns:\n",
    "        dict: Analysis results\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"GKE OBJECTIVE A ANALYSIS\")\n",
    "    print(\"Historical Habitat Dynamics (1984-2024)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Create output directories\n",
    "    for subdir in ['tables', 'figures', 'rasters']:\n",
    "        os.makedirs(os.path.join(output_dir, subdir), exist_ok=True)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Check input files\n",
    "    print(\"\\nChecking input data files...\")\n",
    "    rasters_found = {}\n",
    "    for year, path in lulc_rasters.items():\n",
    "        if os.path.exists(path):\n",
    "            rasters_found[year] = path\n",
    "            print(f\"  ✓ {year}: {os.path.basename(path)}\")\n",
    "        else:\n",
    "            print(f\"  ✗ {year}: NOT FOUND\")\n",
    "    \n",
    "    boundaries_found = {}\n",
    "    for name, path in boundaries.items():\n",
    "        if os.path.exists(path):\n",
    "            boundaries_found[name] = path\n",
    "            print(f\"  ✓ {name}: {os.path.basename(path)}\")\n",
    "        else:\n",
    "            print(f\"  ✗ {name}: NOT FOUND\")\n",
    "    \n",
    "    if len(rasters_found) == 0:\n",
    "        print(\"\\n⚠ WARNING: No rasters found! Please check file paths.\")\n",
    "        return None\n",
    "    \n",
    "    # 1. GKE-Wide Analysis\n",
    "    if \"gke\" in boundaries_found:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"GKE-WIDE LAND COVER ANALYSIS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        gke_boundary = load_boundary(boundaries_found[\"gke\"])\n",
    "        df_gke = analyze_zone(\"GKE\", gke_boundary, rasters_found, Config.YEARS)\n",
    "        \n",
    "        output_path = get_output_path(output_dir, \"Table_GKE_Wide_Composition.csv\")\n",
    "        df_gke.to_csv(output_path, index=False)\n",
    "        print(f\"✓ Saved: {os.path.basename(output_path)}\")\n",
    "        \n",
    "        results['gke_composition'] = df_gke\n",
    "    \n",
    "    # 2. KNP Analysis\n",
    "    if \"knp\" in boundaries_found:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"KAFUE NATIONAL PARK ANALYSIS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        knp_boundary = load_boundary(boundaries_found[\"knp\"])\n",
    "        df_knp = analyze_zone(\"KNP\", knp_boundary, rasters_found, Config.YEARS)\n",
    "        \n",
    "        output_path = get_output_path(output_dir, \"Table_KNP_Composition.csv\")\n",
    "        df_knp.to_csv(output_path, index=False)\n",
    "        print(f\"✓ Saved: {os.path.basename(output_path)}\")\n",
    "        \n",
    "        results['knp_composition'] = df_knp\n",
    "    \n",
    "    # 3. GMA Analysis\n",
    "    if \"gma\" in boundaries_found:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"GAME MANAGEMENT AREAS ANALYSIS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        gma_boundary = load_boundary(boundaries_found[\"gma\"])\n",
    "        \n",
    "        # Check for name column\n",
    "        name_cols = ['NAME', 'GMA_NAME', 'Zone_Name', 'name']\n",
    "        gma_name_col = None\n",
    "        for col in name_cols:\n",
    "            if col in gma_boundary.columns:\n",
    "                gma_name_col = col\n",
    "                break\n",
    "        \n",
    "        if gma_name_col:\n",
    "            gma_names = gma_boundary[gma_name_col].unique()\n",
    "            print(f\"Found {len(gma_names)} GMAs\")\n",
    "            \n",
    "            for gma_name in gma_names:\n",
    "                gma_single = gma_boundary[gma_boundary[gma_name_col] == gma_name]\n",
    "                df_gma = analyze_zone(gma_name, gma_single, rasters_found, Config.YEARS)\n",
    "                \n",
    "                safe_name = gma_name.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "                output_path = get_output_path(output_dir, f\"Table_{safe_name}_Composition.csv\")\n",
    "                df_gma.to_csv(output_path, index=False)\n",
    "        \n",
    "        results['gma_analysis'] = True\n",
    "    \n",
    "    # 4. Transition Matrices\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CHANGE DETECTION ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    years_available = sorted(rasters_found.keys())\n",
    "    \n",
    "    for i in range(len(years_available) - 1):\n",
    "        y1, y2 = years_available[i], years_available[i+1]\n",
    "        print(f\"\\nCalculating transition matrix {y1} → {y2}...\")\n",
    "        \n",
    "        trans_matrix = calculate_transition_matrix(\n",
    "            rasters_found[y1], \n",
    "            rasters_found[y2]\n",
    "        )\n",
    "        \n",
    "        output_path = get_output_path(output_dir, f\"Table_Transition_{y1}_{y2}.csv\")\n",
    "        trans_matrix.to_csv(output_path)\n",
    "        print(f\"✓ Saved: {os.path.basename(output_path)}\")\n",
    "    \n",
    "    results['transition_matrices'] = True\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ANALYSIS COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    n_tables = len(glob.glob(os.path.join(output_dir, \"tables\", \"*.csv\")))\n",
    "    n_figures = len(glob.glob(os.path.join(output_dir, \"figures\", \"*.png\")))\n",
    "    n_rasters = len(glob.glob(os.path.join(output_dir, \"rasters\", \"*.tif\")))\n",
    "    \n",
    "    print(f\"\\nOutput Summary:\")\n",
    "    print(f\"  Tables: {n_tables} CSV files\")\n",
    "    print(f\"  Figures: {n_figures} PNG files\")\n",
    "    print(f\"  Rasters: {n_rasters} TIF files\")\n",
    "    print(f\"\\nOutput directory: {output_dir}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2033bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration - UPDATE THESE PATHS\n",
    "    BASE_DIR = os.getcwd()\n",
    "    DATA_DIR = os.path.join(BASE_DIR, \"D:/Publication/Habitat Loss in the Greater Kafue Ecosystem/Thesis_anlysis/Sable/data/data\")\n",
    "    OUTPUT_DIR = os.path.join(BASE_DIR, \"D:/Publication/Habitat Loss in the Greater Kafue Ecosystem/Thesis_anlysis/Final/outputs/objective_a/figures\")\n",
    "    \n",
    "    # Input file paths\n",
    "    LULC_RASTERS = {\n",
    "        1984: os.path.join(DATA_DIR, \"GKE_1984.tif\"),\n",
    "        1994: os.path.join(DATA_DIR, \"GKE_1994.tif\"),\n",
    "        2004: os.path.join(DATA_DIR, \"GKE_2004.tif\"),\n",
    "        2014: os.path.join(DATA_DIR, \"GKE_2014.tif\"),\n",
    "        2024: os.path.join(DATA_DIR, \"GKE_2024.tif\"),\n",
    "    }\n",
    "    \n",
    "    BOUNDARIES = {\n",
    "        \"gke\": os.path.join(DATA_DIR, \"GKE_Boundary.shp\"),\n",
    "        \"knp\": os.path.join(DATA_DIR, \"nationalParks.shp\"),\n",
    "        \"gma\": os.path.join(DATA_DIR, \"GMA.shp\"),\n",
    "        \"roads\": os.path.join(DATA_DIR, \"Roads.shp\"),\n",
    "    }\n",
    "    \n",
    "    # Run analysis\n",
    "    results = run_objective_a_analysis(DATA_DIR, OUTPUT_DIR, LULC_RASTERS, BOUNDARIES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
