{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9405a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "Susceptibility Mapping and CA-Markov Projections\n",
    "================================================================================\n",
    "\n",
    "Objective B/C: Habitat Loss Drivers and Future Projections - Greater Kafue Ecosystem\n",
    "\n",
    "This script generates:\n",
    "    - Habitat loss susceptibility maps from Random Forest probabilities\n",
    "    - Transition matrices for CA-Markov modeling\n",
    "    - Future land cover projections under multiple scenarios\n",
    "\n",
    "Author: Gift Mulenga\n",
    "Institution: Copperbelt University, Zambia\n",
    "Research: MSc Thesis - Tropical Ecology\n",
    "\n",
    "Requirements:\n",
    "    - rasterio\n",
    "    - numpy\n",
    "    - pandas\n",
    "    - matplotlib\n",
    "    - scikit-learn\n",
    "    - joblib\n",
    "    - scipy\n",
    "    - geopandas\n",
    "\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap, BoundaryNorm\n",
    "from matplotlib.patches import Patch\n",
    "import joblib\n",
    "from scipy import ndimage\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, confusion_matrix\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c401efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration for susceptibility mapping and CA-Markov projections.\"\"\"\n",
    "    \n",
    "    # Directory Configuration - UPDATE THESE PATHS\n",
    "    BASE_DIR = r\"E:/Research/Msc_Tropical_Ecology/GKE_Objective_B\"\n",
    "    LC_DIR = r\"D:/Publication/Habitat Loss in the Greater Kafue Ecosystem/data\"\n",
    "    DRIVER_BASE_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "    MODEL_DIR = os.path.join(BASE_DIR, \"results\")\n",
    "    \n",
    "    OUTPUT_DIR = os.path.join(BASE_DIR, \"results\")\n",
    "    FIGURES_DIR = os.path.join(BASE_DIR, \"figures\")\n",
    "    TABLES_DIR = os.path.join(BASE_DIR, \"tables\")\n",
    "    MAP_DIR = os.path.join(BASE_DIR, \"maps\")\n",
    "    PROJECTION_DIR = os.path.join(BASE_DIR, \"projections\")\n",
    "    \n",
    "    # Land cover files\n",
    "    LC_FILES = {\n",
    "        1984: os.path.join(LC_DIR, \"GKE_1984.tif\"),\n",
    "        1994: os.path.join(LC_DIR, \"GKE_1994.tif\"),\n",
    "        2004: os.path.join(LC_DIR, \"GKE_2004.tif\"),\n",
    "        2014: os.path.join(LC_DIR, \"GKE_2014.tif\"),\n",
    "        2024: os.path.join(LC_DIR, \"GKE_2024.tif\"),\n",
    "    }\n",
    "    \n",
    "    # Driver files (14 variables)\n",
    "    DRIVER_FILES = {\n",
    "        'dist_roads': ('proximity', 'dist_roads.tif'),\n",
    "        'dist_settlements': ('proximity', 'dist_settlements.tif'),\n",
    "        'dist_rivers': ('proximity', 'dist_rivers.tif'),\n",
    "        'dist_knp': ('proximity', 'dist_knp.tif'),\n",
    "        'pop_density': ('socioeconomic', 'pop_density.tif'),\n",
    "        'pop_change': ('socioeconomic', 'pop_change.tif'),\n",
    "        'pct_cultivated': ('socioeconomic', 'pct_cultivated.tif'),\n",
    "        'protection_status': ('conservation', 'protection_status.tif'),\n",
    "        'elevation': ('topographic', 'elevation.tif'),\n",
    "        'slope': ('topographic', 'slope.tif'),\n",
    "        'aspect': ('topographic', 'aspect.tif'),\n",
    "        'twi': ('topographic', 'twi.tif'),\n",
    "        'mean_rainfall': ('climatic', 'mean_rainfall.tif'),\n",
    "        'mean_temp': ('climatic', 'mean_temp.tif')\n",
    "    }\n",
    "    \n",
    "    # Feature order for model\n",
    "    DRIVER_ORDER = [\n",
    "        'dist_roads', 'dist_settlements', 'dist_rivers', 'dist_knp',\n",
    "        'pop_density', 'pop_change', 'pct_cultivated',\n",
    "        'protection_status',\n",
    "        'elevation', 'slope', 'aspect', 'twi',\n",
    "        'mean_rainfall', 'mean_temp'\n",
    "    ]\n",
    "    \n",
    "    # Land cover classes\n",
    "    LC_CLASSES = {\n",
    "        1: 'Built-up', 2: 'Forest', 3: 'Cropland',\n",
    "        4: 'Grassland', 5: 'Bareland', 6: 'Water'\n",
    "    }\n",
    "    \n",
    "    N_CLASSES = 6\n",
    "    \n",
    "    # Susceptibility classification\n",
    "    SUSCEPTIBILITY_BREAKS = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "    SUSCEPTIBILITY_LABELS = ['Very Low', 'Low', 'Moderate', 'High', 'Very High']\n",
    "    SUSCEPTIBILITY_COLORS = ['#2ecc71', '#f1c40f', '#e67e22', '#e74c3c', '#8b0000']\n",
    "    \n",
    "    # CA-Markov parameters\n",
    "    CA_NEIGHBORHOOD_SIZE = 5\n",
    "    CA_WEIGHT_CONTIGUITY = 0.5\n",
    "    N_ENSEMBLE_RUNS = 10\n",
    "    PROJECTION_YEARS = [2030, 2040, 2050]\n",
    "    \n",
    "    # Processing\n",
    "    BATCH_SIZE = 100000\n",
    "    RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc14aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def create_output_directories():\n",
    "    \"\"\"Create output directory structure.\"\"\"\n",
    "    dirs = [Config.OUTPUT_DIR, Config.FIGURES_DIR, Config.TABLES_DIR,\n",
    "            Config.MAP_DIR, Config.PROJECTION_DIR]\n",
    "    for d in dirs:\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "    print(\"✓ Output directories created\")\n",
    "\n",
    "\n",
    "def load_raster(filepath):\n",
    "    \"\"\"Load raster and return data with profile.\"\"\"\n",
    "    with rasterio.open(filepath) as src:\n",
    "        data = src.read(1)\n",
    "        profile = src.profile.copy()\n",
    "        transform = src.transform\n",
    "    return data, profile, transform\n",
    "\n",
    "\n",
    "def save_raster(data, profile, filepath):\n",
    "    \"\"\"Save array as GeoTIFF.\"\"\"\n",
    "    profile.update(dtype=data.dtype, count=1)\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "    with rasterio.open(filepath, 'w', **profile) as dst:\n",
    "        dst.write(data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eddd6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SUSCEPTIBILITY MAPPING\n",
    "# =============================================================================\n",
    "\n",
    "def load_driver_stack(reference_shape):\n",
    "    \"\"\"\n",
    "    Load and stack driver variables.\n",
    "    \n",
    "    Args:\n",
    "        reference_shape: Target shape for alignment\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (stacked array, valid mask, profile)\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Loading Driver Variables ---\")\n",
    "    \n",
    "    drivers = []\n",
    "    profile = None\n",
    "    \n",
    "    for var_name in Config.DRIVER_ORDER:\n",
    "        subfolder, filename = Config.DRIVER_FILES[var_name]\n",
    "        filepath = os.path.join(Config.DRIVER_BASE_DIR, subfolder, filename)\n",
    "        \n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"  ⚠ Missing: {var_name}\")\n",
    "            continue\n",
    "        \n",
    "        with rasterio.open(filepath) as src:\n",
    "            data = src.read(1)\n",
    "            if profile is None:\n",
    "                profile = src.profile.copy()\n",
    "            \n",
    "            # Align if needed\n",
    "            if data.shape != reference_shape:\n",
    "                data = data[:reference_shape[0], :reference_shape[1]]\n",
    "            \n",
    "            drivers.append(data)\n",
    "            print(f\"  ✓ {var_name}: {data.shape}\")\n",
    "    \n",
    "    # Stack\n",
    "    driver_stack = np.stack(drivers, axis=-1)\n",
    "    \n",
    "    # Create valid mask\n",
    "    valid_mask = ~np.any(np.isnan(driver_stack), axis=-1)\n",
    "    \n",
    "    print(f\"\\n  Driver stack shape: {driver_stack.shape}\")\n",
    "    print(f\"  Valid pixels: {np.sum(valid_mask):,}\")\n",
    "    \n",
    "    return driver_stack, valid_mask, profile\n",
    "\n",
    "\n",
    "def generate_susceptibility_map(model_path, driver_stack, valid_mask, profile):\n",
    "    \"\"\"\n",
    "    Generate susceptibility map from Random Forest model.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to trained RF model\n",
    "        driver_stack: Stacked driver variables\n",
    "        valid_mask: Valid data mask\n",
    "        profile: Raster profile\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (probability map, class map)\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Generating Susceptibility Map ---\")\n",
    "    \n",
    "    # Load model\n",
    "    model = joblib.load(model_path)\n",
    "    print(f\"  Model loaded: {model_path}\")\n",
    "    \n",
    "    # Prepare output\n",
    "    shape = driver_stack.shape[:2]\n",
    "    prob_map = np.full(shape, np.nan, dtype=np.float32)\n",
    "    \n",
    "    # Get valid pixels\n",
    "    valid_idx = np.where(valid_mask)\n",
    "    n_pixels = len(valid_idx[0])\n",
    "    \n",
    "    print(f\"  Processing {n_pixels:,} pixels...\")\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in range(0, n_pixels, Config.BATCH_SIZE):\n",
    "        batch_end = min(i + Config.BATCH_SIZE, n_pixels)\n",
    "        batch_rows = valid_idx[0][i:batch_end]\n",
    "        batch_cols = valid_idx[1][i:batch_end]\n",
    "        \n",
    "        # Extract features\n",
    "        X_batch = driver_stack[batch_rows, batch_cols, :]\n",
    "        \n",
    "        # Handle NaN\n",
    "        X_batch = np.nan_to_num(X_batch, nan=0)\n",
    "        \n",
    "        # Predict\n",
    "        proba = model.predict_proba(X_batch)[:, 1]\n",
    "        \n",
    "        # Store\n",
    "        prob_map[batch_rows, batch_cols] = proba\n",
    "        \n",
    "        if (i // Config.BATCH_SIZE) % 100 == 0:\n",
    "            print(f\"    Processed {batch_end:,}/{n_pixels:,} pixels\")\n",
    "    \n",
    "    # Classify\n",
    "    class_map = np.digitize(prob_map, Config.SUSCEPTIBILITY_BREAKS[1:]) + 1\n",
    "    class_map = np.where(np.isnan(prob_map), 0, class_map).astype(np.uint8)\n",
    "    \n",
    "    # Statistics\n",
    "    print(f\"\\n  Susceptibility statistics:\")\n",
    "    print(f\"    Min:  {np.nanmin(prob_map):.4f}\")\n",
    "    print(f\"    Max:  {np.nanmax(prob_map):.4f}\")\n",
    "    print(f\"    Mean: {np.nanmean(prob_map):.4f}\")\n",
    "    \n",
    "    # Save maps\n",
    "    save_raster(prob_map, profile, os.path.join(Config.MAP_DIR, 'susceptibility_probability.tif'))\n",
    "    print(\"  ✓ Saved: susceptibility_probability.tif\")\n",
    "    \n",
    "    save_raster(class_map, profile, os.path.join(Config.MAP_DIR, 'susceptibility_class.tif'))\n",
    "    print(\"  ✓ Saved: susceptibility_class.tif\")\n",
    "    \n",
    "    return prob_map, class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2022e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TRANSITION MATRIX\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_transition_matrix(lc_start, lc_end, n_classes=6):\n",
    "    \"\"\"\n",
    "    Calculate transition probability matrix.\n",
    "    \n",
    "    Args:\n",
    "        lc_start: Start period land cover\n",
    "        lc_end: End period land cover\n",
    "        n_classes: Number of land cover classes\n",
    "        \n",
    "    Returns:\n",
    "        ndarray: Transition probability matrix\n",
    "    \"\"\"\n",
    "    # Align shapes\n",
    "    if lc_start.shape != lc_end.shape:\n",
    "        min_shape = (min(lc_start.shape[0], lc_end.shape[0]),\n",
    "                     min(lc_start.shape[1], lc_end.shape[1]))\n",
    "        lc_start = lc_start[:min_shape[0], :min_shape[1]]\n",
    "        lc_end = lc_end[:min_shape[0], :min_shape[1]]\n",
    "    \n",
    "    # Count transitions\n",
    "    trans_counts = np.zeros((n_classes, n_classes), dtype=np.int64)\n",
    "    valid_mask = (lc_start > 0) & (lc_end > 0) & (lc_start <= n_classes) & (lc_end <= n_classes)\n",
    "    \n",
    "    for i in range(1, n_classes + 1):\n",
    "        for j in range(1, n_classes + 1):\n",
    "            trans_counts[i-1, j-1] = np.sum((lc_start == i) & (lc_end == j) & valid_mask)\n",
    "    \n",
    "    # Convert to probabilities\n",
    "    row_sums = trans_counts.sum(axis=1, keepdims=True)\n",
    "    row_sums[row_sums == 0] = 1\n",
    "    trans_probs = trans_counts / row_sums\n",
    "    \n",
    "    return trans_probs\n",
    "\n",
    "\n",
    "def annualize_matrix(trans_matrix, n_years):\n",
    "    \"\"\"\n",
    "    Convert multi-year transition matrix to annual rates.\n",
    "    \n",
    "    Args:\n",
    "        trans_matrix: Period transition matrix\n",
    "        n_years: Number of years in period\n",
    "        \n",
    "    Returns:\n",
    "        ndarray: Annual transition matrix\n",
    "    \"\"\"\n",
    "    from scipy.linalg import logm, expm\n",
    "    \n",
    "    n_classes = trans_matrix.shape[0]\n",
    "    \n",
    "    try:\n",
    "        P_adjusted = trans_matrix + 1e-10\n",
    "        P_adjusted = P_adjusted / P_adjusted.sum(axis=1, keepdims=True)\n",
    "        \n",
    "        log_P = logm(P_adjusted)\n",
    "        annual_log = log_P / n_years\n",
    "        annual_matrix = expm(annual_log)\n",
    "        \n",
    "        annual_matrix = np.real(annual_matrix)\n",
    "        annual_matrix = np.clip(annual_matrix, 0, 1)\n",
    "        annual_matrix = annual_matrix / annual_matrix.sum(axis=1, keepdims=True)\n",
    "        \n",
    "    except Exception:\n",
    "        # Fallback to linear approximation\n",
    "        identity = np.eye(n_classes)\n",
    "        annual_matrix = identity + (trans_matrix - identity) / n_years\n",
    "        annual_matrix = np.clip(annual_matrix, 0, 1)\n",
    "        annual_matrix = annual_matrix / annual_matrix.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    return annual_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb802a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CA-MARKOV SIMULATION\n",
    "# =============================================================================\n",
    "\n",
    "def ca_markov_step(current_lc, trans_matrix, susceptibility, knp_mask=None, \n",
    "                   w_contiguity=0.5, random_state=None):\n",
    "    \"\"\"\n",
    "    Perform one step of CA-Markov simulation.\n",
    "    \n",
    "    Args:\n",
    "        current_lc: Current land cover array\n",
    "        trans_matrix: Annual transition matrix\n",
    "        susceptibility: Susceptibility map\n",
    "        knp_mask: Protected area mask\n",
    "        w_contiguity: Weight for neighborhood contiguity\n",
    "        random_state: Random seed\n",
    "        \n",
    "    Returns:\n",
    "        ndarray: Updated land cover\n",
    "    \"\"\"\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    shape = current_lc.shape\n",
    "    new_lc = current_lc.copy()\n",
    "    \n",
    "    # Create neighborhood kernel\n",
    "    kernel_size = Config.CA_NEIGHBORHOOD_SIZE\n",
    "    kernel = np.ones((kernel_size, kernel_size)) / (kernel_size ** 2)\n",
    "    \n",
    "    # Calculate neighborhood composition for each class\n",
    "    neighborhood_probs = {}\n",
    "    for c in range(1, Config.N_CLASSES + 1):\n",
    "        class_mask = (current_lc == c).astype(float)\n",
    "        neighborhood_probs[c] = ndimage.convolve(class_mask, kernel, mode='constant')\n",
    "    \n",
    "    # Process each pixel\n",
    "    valid_mask = (current_lc > 0) & (current_lc <= Config.N_CLASSES)\n",
    "    valid_idx = np.where(valid_mask)\n",
    "    \n",
    "    for i in range(len(valid_idx[0])):\n",
    "        row, col = valid_idx[0][i], valid_idx[1][i]\n",
    "        current_class = current_lc[row, col]\n",
    "        \n",
    "        # Skip protected areas\n",
    "        if knp_mask is not None and knp_mask[row, col]:\n",
    "            continue\n",
    "        \n",
    "        # Get base transition probabilities\n",
    "        trans_probs = trans_matrix[current_class - 1].copy()\n",
    "        \n",
    "        # Modify by susceptibility\n",
    "        susc = susceptibility[row, col] if not np.isnan(susceptibility[row, col]) else 0.5\n",
    "        \n",
    "        # Modify by neighborhood\n",
    "        for c in range(1, Config.N_CLASSES + 1):\n",
    "            neigh_prob = neighborhood_probs[c][row, col]\n",
    "            trans_probs[c-1] = (1 - w_contiguity) * trans_probs[c-1] + w_contiguity * neigh_prob\n",
    "        \n",
    "        # Normalize\n",
    "        trans_probs = trans_probs / trans_probs.sum()\n",
    "        \n",
    "        # Sample new class\n",
    "        new_class = np.random.choice(range(1, Config.N_CLASSES + 1), p=trans_probs)\n",
    "        new_lc[row, col] = new_class\n",
    "    \n",
    "    return new_lc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d6556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "def main(run_susceptibility=True, run_projections=False):\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"SUSCEPTIBILITY MAPPING AND CA-MARKOV PROJECTIONS\")\n",
    "    print(\"Greater Kafue Ecosystem\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nTimestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    create_output_directories()\n",
    "    \n",
    "    # Load reference land cover\n",
    "    print(\"\\n--- Loading Reference Data ---\")\n",
    "    lc_2024, profile, transform = load_raster(Config.LC_FILES[2024])\n",
    "    print(f\"  Reference shape: {lc_2024.shape}\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    if run_susceptibility:\n",
    "        # Load drivers\n",
    "        driver_stack, valid_mask, _ = load_driver_stack(lc_2024.shape)\n",
    "        \n",
    "        # Generate susceptibility\n",
    "        model_path = os.path.join(Config.MODEL_DIR, 'rf_model.joblib')\n",
    "        prob_map, class_map = generate_susceptibility_map(\n",
    "            model_path, driver_stack, valid_mask, profile\n",
    "        )\n",
    "        \n",
    "        # Calculate area statistics\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SUSCEPTIBILITY STATISTICS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        pixel_area_ha = abs(profile['transform'][0] * profile['transform'][4]) / 10000\n",
    "        \n",
    "        stats = []\n",
    "        for i, label in enumerate(Config.SUSCEPTIBILITY_LABELS, 1):\n",
    "            count = np.sum(class_map == i)\n",
    "            area = count * pixel_area_ha\n",
    "            pct = count / np.sum(class_map > 0) * 100 if np.sum(class_map > 0) > 0 else 0\n",
    "            stats.append({'Class': label, 'Area_ha': area, 'Percent': pct})\n",
    "            print(f\"  {label}: {area:,.0f} ha ({pct:.1f}%)\")\n",
    "        \n",
    "        stats_df = pd.DataFrame(stats)\n",
    "        stats_df.to_csv(os.path.join(Config.TABLES_DIR, 'Table_Susceptibility_Area.csv'), index=False)\n",
    "        \n",
    "        results['susceptibility'] = {'prob_map': prob_map, 'class_map': class_map}\n",
    "    \n",
    "    if run_projections:\n",
    "        # Load land cover maps\n",
    "        print(\"\\n--- Loading Land Cover Maps ---\")\n",
    "        lc_1984, _, _ = load_raster(Config.LC_FILES[1984])\n",
    "        lc_2024, _, _ = load_raster(Config.LC_FILES[2024])\n",
    "        \n",
    "        # Calculate transition matrix\n",
    "        print(\"\\n--- Calculating Transition Matrix ---\")\n",
    "        trans_40yr = calculate_transition_matrix(lc_1984, lc_2024)\n",
    "        trans_annual = annualize_matrix(trans_40yr, 40)\n",
    "        \n",
    "        # Save transition matrices\n",
    "        class_names = list(Config.LC_CLASSES.values())\n",
    "        trans_df = pd.DataFrame(trans_annual, index=class_names, columns=class_names)\n",
    "        trans_df.to_csv(os.path.join(Config.TABLES_DIR, 'Table_Transition_Matrix_Annual.csv'))\n",
    "        \n",
    "        print(\"\\n  Key annual transitions:\")\n",
    "        for i, from_class in enumerate(class_names):\n",
    "            for j, to_class in enumerate(class_names):\n",
    "                if i != j and trans_annual[i, j] > 0.003:\n",
    "                    print(f\"    {from_class} → {to_class}: {trans_annual[i, j]*100:.3f}%\")\n",
    "        \n",
    "        results['transition_matrix'] = trans_annual\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nOutputs:\")\n",
    "    print(f\"  Maps: {Config.MAP_DIR}\")\n",
    "    print(f\"  Tables: {Config.TABLES_DIR}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main(run_susceptibility=True, run_projections=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s123-mission",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
